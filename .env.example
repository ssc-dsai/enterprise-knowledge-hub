# Docker bootstrap variables

# Frontend
DB_USER=admin
DB_PASSWORD=<pwd>
DB=rag
DB_HOST=localhost
DB_PORT=5432

# API

#TODO

# Queue
RABBITMQ_URL=amqp://guest:guest@127.0.0.1:5672/

# PG
POSTGRES_USER=admin
POSTGRES_PASSWORD=<pwd>
POSTGRES_DB=rag

# PG readonly
#POSTGRES_USER=readonly_user
#POSTGRES_PASSWORD=readonly

# PG Admin
PGADMIN_DEFAULT_EMAIL=<some@email.com>
PGADMIN_DEFAULT_PASSWORD=admin

# Embedding Dimension (max dimension for embeddings, typically 512 or 1024)
WIKIPEDIA_EMBEDDING_MAX_DIMENSION=512
WIKIPEDIA_EMBEDDING_MODEL_BACKEND=LLAMA # Options: LLAMA, SENTENCE_TRANSFORMER
WIKIPEDIA_EMBEDDING_MODEL_CLEANUP=False
WIKIPEDIA_EMBEDDING_MODEL_BATCH_SIZE=4
WIKIPEDIA_EMBEDDING_MODEL_MAX_LENGTH=4096
WIKIPEDIA_EMBEDDING_MODEL_DTYPE=float16 # Options: float16, float32

# LLAMA CONFIGS (please view pyproject.toml for more system specific build instructions, see [tool.uv] section)

# for linux (with gpu support)
LLAMA_CUDA=1

DB_SKIP_STORE=True

PYTORCH_ALLOC_CONF="max_split_size_mb:128,garbage_collection_threshold:0.6,expandable_segments:False"
PYTORCH_CUDA_GPU_CAP=0.8

# would extract files while reading bz2 file, be careful with disk space...
DEBUG_EXTRACTION=True
