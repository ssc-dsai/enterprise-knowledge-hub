[project]
name = "enterprise-knowledge-hub"
version = "0.1.0"
description = "Enterprise Knowledge hub to index the documents from various sources"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "accelerate>=1.12.0",
    "fastapi[standard]>=0.124.4",
    "langchain>=1.2.1",
    "llama-cpp-python>=0.3.16",
    "pika>=1.3.2",
    "sentence-transformers>=5.2.0",
    "torch>=2.9.1",
    "transformers>=4.57.3",
]

[dependency-groups]
dev = [
    "pylint>=4.0.4",
]

[tool.uv]
# DOC: https://github.com/abetlen/llama-cpp-python?tab=readme-ov-file#installation
# llama-cpp-python build configuration
# Uncomment ONE of the following extra-build-variables lines based on your hardware:
# follow up with (if rebuilding):
# uv sync --upgrade --no-cache --reinstall-package llama-cpp-python

# CPU only (default) - no extra args needed
# extra-build-variables = {}

# CUDA support (NVIDIA GPU)
extra-build-variables = { llama-cpp-python = { CMAKE_ARGS = "-DGGML_CUDA=on -DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc" } }

# Metal support (Apple Silicon)
# extra-build-variables = { llama-cpp-python = { CMAKE_ARGS = "-DGGML_METAL=on" } }

# OpenBLAS support
# extra-build-variables = { llama-cpp-python = { CMAKE_ARGS = "-DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS" } }